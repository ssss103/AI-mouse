import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx

# å¯¼å…¥å¹¶åº”ç”¨matplotlibæ ·å¼é…ç½®
try:
    from matplotlib_config import setup_matplotlib_style
    setup_matplotlib_style()
except ImportError:
    print("è­¦å‘Š: æ— æ³•å¯¼å…¥matplotlib_configï¼Œä½¿ç”¨é»˜è®¤å­—ä½“è®¾ç½®")
from scipy.stats import pearsonr, spearmanr
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans, SpectralClustering
import community as community_louvain
from collections import defaultdict, Counter
import warnings
warnings.filterwarnings('ignore')

class KeyNeuronCommunityDemo:
    """
    å…³é”®ç¥ç»å…ƒç¤¾åŒºç»“æ„åˆ†ææ¼”ç¤ºå™¨
    """
    
    def __init__(self, data_path):
        """
        åˆå§‹åŒ–æ¼”ç¤ºå™¨
        
        Args:
            data_path: ç¥ç»å…ƒæ´»åŠ¨æ•°æ®è·¯å¾„
        """
        self.data_path = data_path
        self.df = None
        self.key_neurons = None
        self.networks = {}
        self.communities = {}
        
    def load_data(self):
        """åŠ è½½æ•°æ®"""
        print("=== åŠ è½½æ•°æ® ===")
        
        # åŠ è½½ç¥ç»å…ƒæ´»åŠ¨æ•°æ®
        self.df = pd.read_csv(self.data_path)
        neuron_cols = [col for col in self.df.columns if col.startswith('Neuron_')]
        
        print(f"ç¥ç»å…ƒæ´»åŠ¨æ•°æ®:")
        print(f"  - è¡Œä¸ºçŠ¶æ€: {len(self.df)} ä¸ª")
        print(f"  - ç¥ç»å…ƒæ€»æ•°: {len(neuron_cols)} ä¸ª")
        print(f"  - è¡Œä¸ºç±»å‹: {list(self.df['Behavior'].unique())}")
        
        # è¯†åˆ«å…³é”®ç¥ç»å…ƒï¼ˆåŸºäºæ´»åŠ¨æ°´å¹³ï¼‰
        self.identify_key_neurons_by_activity()
        
    def identify_key_neurons_by_activity(self, top_n=20):
        """
        åŸºäºæ´»åŠ¨æ°´å¹³è¯†åˆ«å…³é”®ç¥ç»å…ƒ
        
        Args:
            top_n: é€‰æ‹©çš„å…³é”®ç¥ç»å…ƒæ•°é‡
        """
        print(f"\n=== åŸºäºæ´»åŠ¨æ°´å¹³è¯†åˆ«å…³é”®ç¥ç»å…ƒ ===")
        
        neuron_cols = [col for col in self.df.columns if col.startswith('Neuron_')]
        
        # è®¡ç®—æ¯ä¸ªç¥ç»å…ƒçš„å¹³å‡æ´»åŠ¨æ°´å¹³å’Œå˜å¼‚æ€§
        neuron_stats = {}
        for neuron in neuron_cols:
            activity_values = self.df[neuron].values
            mean_activity = np.mean(activity_values)
            std_activity = np.std(activity_values)
            max_activity = np.max(activity_values)
            
            # ç»¼åˆè¯„åˆ†ï¼šè€ƒè™‘å¹³å‡æ´»åŠ¨æ°´å¹³å’Œå˜å¼‚æ€§
            score = mean_activity + std_activity * 0.5
            
            neuron_stats[neuron] = {
                'mean': mean_activity,
                'std': std_activity,
                'max': max_activity,
                'score': score
            }
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ç¥ç»å…ƒä½œä¸ºå…³é”®ç¥ç»å…ƒ
        sorted_neurons = sorted(neuron_stats.items(), key=lambda x: x[1]['score'], reverse=True)
        self.key_neurons = [neuron for neuron, stats in sorted_neurons[:top_n]]
        
        print(f"é€‰æ‹©äº† {len(self.key_neurons)} ä¸ªå…³é”®ç¥ç»å…ƒ")
        print("å‰10ä¸ªå…³é”®ç¥ç»å…ƒ:")
        for i, (neuron, stats) in enumerate(sorted_neurons[:10]):
            print(f"  {i+1}. {neuron}: å¹³å‡={stats['mean']:.3f}, æ ‡å‡†å·®={stats['std']:.3f}, å¾—åˆ†={stats['score']:.3f}")
        
        return self.key_neurons
    
    def build_activity_similarity_networks(self, similarity_method='euclidean'):
        """
        åŸºäºæ´»åŠ¨æ¨¡å¼ç›¸ä¼¼æ€§æ„å»ºç½‘ç»œ
        
        Args:
            similarity_method: ç›¸ä¼¼æ€§è®¡ç®—æ–¹æ³•
        """
        print(f"\n=== æ„å»ºæ´»åŠ¨ç›¸ä¼¼æ€§ç½‘ç»œ ===")
        print(f"ç›¸ä¼¼æ€§æ–¹æ³•: {similarity_method}")
        
        behaviors = self.df['Behavior'].unique()
        
        # è·å–å…³é”®ç¥ç»å…ƒçš„æ´»åŠ¨æ•°æ®
        key_neuron_data = self.df[self.key_neurons].values  # shape: (n_behaviors, n_key_neurons)
        
        # è®¡ç®—ç¥ç»å…ƒé—´çš„ç›¸ä¼¼æ€§çŸ©é˜µ
        n_neurons = len(self.key_neurons)
        similarity_matrix = np.zeros((n_neurons, n_neurons))
        
        for i in range(n_neurons):
            for j in range(n_neurons):
                if i == j:
                    similarity_matrix[i, j] = 1.0
                else:
                    # è®¡ç®—ç¥ç»å…ƒiå’Œjåœ¨æ‰€æœ‰è¡Œä¸ºçŠ¶æ€ä¸‹çš„æ´»åŠ¨ç›¸ä¼¼æ€§
                    activity_i = key_neuron_data[:, i]
                    activity_j = key_neuron_data[:, j]
                    
                    if similarity_method == 'euclidean':
                        # æ¬§æ°è·ç¦»çš„ç›¸ä¼¼æ€§
                        distance = np.sqrt(np.sum((activity_i - activity_j) ** 2))
                        similarity = 1 / (1 + distance)  # è½¬æ¢ä¸ºç›¸ä¼¼æ€§
                    elif similarity_method == 'cosine':
                        # ä½™å¼¦ç›¸ä¼¼æ€§
                        norm_i = np.linalg.norm(activity_i)
                        norm_j = np.linalg.norm(activity_j)
                        if norm_i > 0 and norm_j > 0:
                            similarity = np.dot(activity_i, activity_j) / (norm_i * norm_j)
                        else:
                            similarity = 0
                    elif similarity_method == 'correlation':
                        # çš®å°”é€Šç›¸å…³ç³»æ•°çš„ç»å¯¹å€¼
                        if len(activity_i) > 1:
                            similarity = abs(np.corrcoef(activity_i, activity_j)[0, 1])
                            if np.isnan(similarity):
                                similarity = 0
                        else:
                            similarity = 0
                    else:
                        similarity = 0
                    
                    similarity_matrix[i, j] = similarity
        
        # æ„å»ºç½‘ç»œå›¾
        G = nx.Graph()
        
        # æ·»åŠ èŠ‚ç‚¹
        for neuron in self.key_neurons:
            G.add_node(neuron)
        
        # è®¾ç½®è¿æ¥é˜ˆå€¼ï¼ˆé€‰æ‹©ç›¸ä¼¼æ€§å‰30%çš„è¿æ¥ï¼‰
        threshold = np.percentile(similarity_matrix[similarity_matrix < 1.0], 70)
        
        # æ·»åŠ è¾¹
        edge_count = 0
        for i in range(n_neurons):
            for j in range(i+1, n_neurons):
                if similarity_matrix[i, j] >= threshold:
                    G.add_edge(
                        self.key_neurons[i], 
                        self.key_neurons[j], 
                        weight=similarity_matrix[i, j],
                        similarity=similarity_matrix[i, j]
                    )
                    edge_count += 1
        
        self.networks['combined'] = {
            'graph': G,
            'similarity_matrix': similarity_matrix,
            'edge_count': edge_count,
            'density': nx.density(G),
            'threshold': threshold
        }
        
        print(f"ç½‘ç»œæ„å»ºå®Œæˆ:")
        print(f"  èŠ‚ç‚¹æ•°: {G.number_of_nodes()}")
        print(f"  è¾¹æ•°: {edge_count}")
        print(f"  ç½‘ç»œå¯†åº¦: {nx.density(G):.3f}")
        print(f"  ç›¸ä¼¼æ€§é˜ˆå€¼: {threshold:.3f}")
        
        return G
    
    def detect_communities(self, methods=['louvain', 'spectral', 'hierarchical']):
        """
        æ£€æµ‹ç¤¾åŒºç»“æ„
        
        Args:
            methods: ç¤¾åŒºæ£€æµ‹æ–¹æ³•åˆ—è¡¨
        """
        print(f"\n=== ç¤¾åŒºæ£€æµ‹ ===")
        
        G = self.networks['combined']['graph']
        
        if G.number_of_nodes() == 0:
            print("ç½‘ç»œä¸­æ²¡æœ‰èŠ‚ç‚¹ï¼Œæ— æ³•è¿›è¡Œç¤¾åŒºæ£€æµ‹")
            return
        
        communities = {}
        
        # 1. Louvainç®—æ³•
        if 'louvain' in methods and G.number_of_edges() > 0:
            try:
                louvain_communities = community_louvain.best_partition(G)
                n_communities = len(set(louvain_communities.values()))
                modularity = community_louvain.modularity(louvain_communities, G)
                
                communities['louvain'] = {
                    'partition': louvain_communities,
                    'n_communities': n_communities,
                    'modularity': modularity
                }
                print(f"Louvainç®—æ³•: {n_communities} ä¸ªç¤¾åŒº, æ¨¡å—åº¦ = {modularity:.3f}")
                
                # æ˜¾ç¤ºå„ç¤¾åŒºçš„ç¥ç»å…ƒ
                community_neurons = defaultdict(list)
                for neuron, comm_id in louvain_communities.items():
                    community_neurons[comm_id].append(neuron)
                
                for comm_id, neurons in community_neurons.items():
                    print(f"  ç¤¾åŒº {comm_id}: {neurons}")
                    
            except Exception as e:
                print(f"Louvainç®—æ³•å¤±è´¥: {e}")
        
        # 2. åŸºäºç›¸ä¼¼æ€§çŸ©é˜µçš„å±‚æ¬¡èšç±»
        if 'hierarchical' in methods:
            try:
                similarity_matrix = self.networks['combined']['similarity_matrix']
                distance_matrix = 1 - similarity_matrix
                
                # åªä½¿ç”¨ä¸Šä¸‰è§’çŸ©é˜µè¿›è¡Œèšç±»
                condensed_distances = []
                n = len(self.key_neurons)
                for i in range(n):
                    for j in range(i+1, n):
                        condensed_distances.append(distance_matrix[i, j])
                
                # æ‰§è¡Œå±‚æ¬¡èšç±»
                linkage_matrix = linkage(condensed_distances, method='ward')
                
                # ç¡®å®šèšç±»æ•°ï¼ˆåŸºäºç½‘ç»œå¯†åº¦ï¼‰
                density = self.networks['combined']['density']
                if density > 0.3:
                    n_clusters = max(2, min(6, len(self.key_neurons) // 4))
                else:
                    n_clusters = max(2, min(4, len(self.key_neurons) // 5))
                
                cluster_labels = fcluster(linkage_matrix, n_clusters, criterion='maxclust')
                
                hierarchical_communities = {
                    neuron: label-1 for neuron, label in zip(self.key_neurons, cluster_labels)
                }
                
                communities['hierarchical'] = {
                    'partition': hierarchical_communities,
                    'n_communities': n_clusters,
                    'linkage_matrix': linkage_matrix
                }
                
                print(f"å±‚æ¬¡èšç±»: {n_clusters} ä¸ªç¤¾åŒº")
                
                # æ˜¾ç¤ºå„ç¤¾åŒºçš„ç¥ç»å…ƒ
                community_neurons = defaultdict(list)
                for neuron, comm_id in hierarchical_communities.items():
                    community_neurons[comm_id].append(neuron)
                
                for comm_id, neurons in community_neurons.items():
                    print(f"  ç¤¾åŒº {comm_id}: {neurons}")
                    
            except Exception as e:
                print(f"å±‚æ¬¡èšç±»å¤±è´¥: {e}")
        
        # 3. K-meansèšç±»ï¼ˆåŸºäºç¥ç»å…ƒæ´»åŠ¨æ¨¡å¼ï¼‰
        if 'kmeans' in methods:
            try:
                # ä½¿ç”¨ç¥ç»å…ƒçš„æ´»åŠ¨æ•°æ®è¿›è¡ŒK-meansèšç±»
                neuron_activity = self.df[self.key_neurons].T.values  # shape: (n_neurons, n_behaviors)
                
                # æ ‡å‡†åŒ–æ•°æ®
                scaler = StandardScaler()
                scaled_activity = scaler.fit_transform(neuron_activity)
                
                # ç¡®å®šèšç±»æ•°
                n_clusters = max(2, min(5, len(self.key_neurons) // 4))
                
                kmeans = KMeans(n_clusters=n_clusters, random_state=42)
                cluster_labels = kmeans.fit_predict(scaled_activity)
                
                kmeans_communities = {
                    neuron: label for neuron, label in zip(self.key_neurons, cluster_labels)
                }
                
                communities['kmeans'] = {
                    'partition': kmeans_communities,
                    'n_communities': n_clusters,
                    'model': kmeans
                }
                
                print(f"K-meansèšç±»: {n_clusters} ä¸ªç¤¾åŒº")
                
                # æ˜¾ç¤ºå„ç¤¾åŒºçš„ç¥ç»å…ƒ
                community_neurons = defaultdict(list)
                for neuron, comm_id in kmeans_communities.items():
                    community_neurons[comm_id].append(neuron)
                
                for comm_id, neurons in community_neurons.items():
                    print(f"  ç¤¾åŒº {comm_id}: {neurons}")
                    
            except Exception as e:
                print(f"K-meansèšç±»å¤±è´¥: {e}")
        
        self.communities['combined'] = communities
        return communities
    
    def analyze_behavior_specific_patterns(self):
        """åˆ†æä¸åŒè¡Œä¸ºçŠ¶æ€ä¸‹çš„ç¥ç»å…ƒæ´»åŠ¨æ¨¡å¼"""
        print(f"\n=== è¡Œä¸ºç‰¹å¼‚æ€§æ¨¡å¼åˆ†æ ===")
        
        behaviors = self.df['Behavior'].unique()
        behavior_patterns = {}
        
        for behavior in behaviors:
            behavior_data = self.df[self.df['Behavior'] == behavior]
            
            if len(behavior_data) > 0:
                # è·å–è¯¥è¡Œä¸ºçŠ¶æ€ä¸‹å…³é”®ç¥ç»å…ƒçš„æ´»åŠ¨
                activity_values = behavior_data[self.key_neurons].iloc[0].values
                
                # è¯†åˆ«é«˜æ´»åŠ¨å’Œä½æ´»åŠ¨çš„ç¥ç»å…ƒ
                mean_activity = np.mean(activity_values)
                std_activity = np.std(activity_values)
                
                high_threshold = mean_activity + 0.5 * std_activity
                low_threshold = mean_activity - 0.5 * std_activity
                
                high_activity_neurons = [neuron for neuron, activity in zip(self.key_neurons, activity_values) 
                                       if activity >= high_threshold]
                low_activity_neurons = [neuron for neuron, activity in zip(self.key_neurons, activity_values) 
                                      if activity <= low_threshold]
                
                behavior_patterns[behavior] = {
                    'high_activity': high_activity_neurons,
                    'low_activity': low_activity_neurons,
                    'mean_activity': mean_activity,
                    'activity_values': dict(zip(self.key_neurons, activity_values))
                }
                
                print(f"{behavior} è¡Œä¸º:")
                print(f"  å¹³å‡æ´»åŠ¨æ°´å¹³: {mean_activity:.3f}")
                print(f"  é«˜æ´»åŠ¨ç¥ç»å…ƒ ({len(high_activity_neurons)}ä¸ª): {high_activity_neurons[:5]}{'...' if len(high_activity_neurons) > 5 else ''}")
                print(f"  ä½æ´»åŠ¨ç¥ç»å…ƒ ({len(low_activity_neurons)}ä¸ª): {low_activity_neurons[:5]}{'...' if len(low_activity_neurons) > 5 else ''}")
        
        return behavior_patterns
    
    def visualize_community_networks(self, save_plots=True):
        """å¯è§†åŒ–ç¤¾åŒºç½‘ç»œç»“æ„"""
        print(f"\n=== ç½‘ç»œå’Œç¤¾åŒºå¯è§†åŒ– ===")
        
        if save_plots:
            import os
            plot_dir = "community_demo_plots"
            if not os.path.exists(plot_dir):
                os.makedirs(plot_dir)
        
        G = self.networks['combined']['graph']
        
        if 'combined' not in self.communities or 'louvain' not in self.communities['combined']:
            print("æ²¡æœ‰å¯ç”¨çš„ç¤¾åŒºæ£€æµ‹ç»“æœ")
            return
        
        partition = self.communities['combined']['louvain']['partition']
        
        # åˆ›å»ºç½‘ç»œå¯è§†åŒ–
        plt.figure(figsize=(14, 10))
        
        if G.number_of_nodes() > 0:
            # è®¾ç½®å¸ƒå±€
            pos = nx.spring_layout(G, k=2, iterations=50, seed=42)
            
            # ç»˜åˆ¶è¾¹
            edges = G.edges()
            if len(edges) > 0:
                edge_weights = [G[u][v]['weight'] for u, v in edges]
                nx.draw_networkx_edges(G, pos, alpha=0.3, width=[w*3 for w in edge_weights], 
                                     edge_color='gray')
            
            # ä¸ºä¸åŒç¤¾åŒºè®¾ç½®ä¸åŒé¢œè‰²
            unique_communities = set(partition.values())
            colors = plt.cm.Set3(np.linspace(0, 1, len(unique_communities)))
            color_map = {comm: colors[i] for i, comm in enumerate(unique_communities)}
            
            # ç»˜åˆ¶èŠ‚ç‚¹
            for community in unique_communities:
                community_nodes = [node for node, comm in partition.items() if comm == community]
                nx.draw_networkx_nodes(G, pos, nodelist=community_nodes, 
                                     node_color=[color_map[community]], 
                                     node_size=500, alpha=0.8,
                                     label=f'ç¤¾åŒº {community}')
            
            # ç»˜åˆ¶æ ‡ç­¾
            nx.draw_networkx_labels(G, pos, font_size=8, font_weight='bold')
            
            plt.title('å…³é”®ç¥ç»å…ƒç½‘ç»œå’Œç¤¾åŒºç»“æ„', fontsize=18, fontweight='bold')
            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=14)
            plt.axis('off')
            
            if save_plots:
                plt.savefig(f"{plot_dir}/community_network.png", dpi=300, bbox_inches='tight')
            plt.show()
        
        # åˆ›å»ºç¤¾åŒºæ´»åŠ¨çƒ­å›¾
        self._plot_community_activity_heatmap(save_plots, plot_dir if save_plots else None)
    
    def _plot_community_activity_heatmap(self, save_plots=True, plot_dir=None):
        """ç»˜åˆ¶ç¤¾åŒºæ´»åŠ¨çƒ­å›¾"""
        
        if 'combined' not in self.communities or 'louvain' not in self.communities['combined']:
            return
        
        partition = self.communities['combined']['louvain']['partition']
        
        # æŒ‰ç¤¾åŒºç»„ç»‡ç¥ç»å…ƒæ•°æ®
        community_data = defaultdict(list)
        community_neurons = defaultdict(list)
        
        for neuron, comm_id in partition.items():
            community_data[comm_id].extend(self.df[neuron].values)
            community_neurons[comm_id].append(neuron)
        
        # åˆ›å»ºçƒ­å›¾æ•°æ®
        behaviors = self.df['Behavior'].unique()
        communities = sorted(partition.values())
        
        heatmap_data = []
        row_labels = []
        
        for comm_id in communities:
            neurons = community_neurons[comm_id]
            for neuron in neurons:
                row_data = []
                for behavior in behaviors:
                    activity = self.df[self.df['Behavior'] == behavior][neuron].iloc[0]
                    row_data.append(activity)
                heatmap_data.append(row_data)
                row_labels.append(f"C{comm_id}_{neuron}")
        
        # ç»˜åˆ¶çƒ­å›¾
        plt.figure(figsize=(8, max(6, len(row_labels) * 0.3)))
        
        sns.heatmap(heatmap_data, 
                   xticklabels=behaviors,
                   yticklabels=row_labels,
                   cmap='viridis',
                   cbar_kws={'label': 'ç¥ç»å…ƒæ´»åŠ¨'})
        
        plt.title('å„ç¤¾åŒºç¥ç»å…ƒåœ¨ä¸åŒè¡Œä¸ºçŠ¶æ€ä¸‹çš„æ´»åŠ¨', fontsize=16, fontweight='bold')
        plt.xlabel('è¡Œä¸ºçŠ¶æ€', fontsize=14, fontweight='bold')
        plt.ylabel('ç¥ç»å…ƒ (æŒ‰ç¤¾åŒºåˆ†ç»„)', fontsize=14, fontweight='bold')
        plt.xticks(fontsize=12, fontweight='bold')
        plt.yticks(fontsize=10, fontweight='bold')
        plt.tight_layout()
        
        if save_plots and plot_dir:
            plt.savefig(f"{plot_dir}/community_activity_heatmap.png", dpi=300, bbox_inches='tight')
        plt.show()
    
    def generate_community_insights(self):
        """ç”Ÿæˆç¤¾åŒºåˆ†ææ´å¯Ÿ"""
        print(f"\n=== ç¤¾åŒºåˆ†ææ´å¯Ÿ ===")
        
        insights = []
        
        if 'combined' in self.communities and 'louvain' in self.communities['combined']:
            louvain_data = self.communities['combined']['louvain']
            partition = louvain_data['partition']
            n_communities = louvain_data['n_communities']
            modularity = louvain_data['modularity']
            
            insights.append(f"ğŸ˜ï¸ **ç¤¾åŒºç»“æ„å‘ç°**:")
            insights.append(f"- è¯†åˆ«å‡º **{n_communities}** ä¸ªç¥ç»å…ƒç¤¾åŒº")
            insights.append(f"- ç½‘ç»œæ¨¡å—åº¦: **{modularity:.3f}** (>0.3è¡¨ç¤ºè‰¯å¥½çš„ç¤¾åŒºç»“æ„)")
            
            # åˆ†æå„ç¤¾åŒºç‰¹å¾
            community_sizes = defaultdict(int)
            for neuron, comm_id in partition.items():
                community_sizes[comm_id] += 1
            
            insights.append(f"\nğŸ“Š **ç¤¾åŒºå¤§å°åˆ†å¸ƒ**:")
            for comm_id, size in sorted(community_sizes.items()):
                insights.append(f"- ç¤¾åŒº {comm_id}: {size} ä¸ªç¥ç»å…ƒ")
            
            # åˆ†æç¤¾åŒºçš„åŠŸèƒ½ç‰¹å¾
            behavior_patterns = self.analyze_behavior_specific_patterns()
            
            insights.append(f"\nğŸ§  **åŠŸèƒ½ç‰¹å¾åˆ†æ**:")
            for behavior, pattern in behavior_patterns.items():
                insights.append(f"- **{behavior}** è¡Œä¸º:")
                insights.append(f"  - é«˜æ´»åŠ¨ç¥ç»å…ƒ: {len(pattern['high_activity'])} ä¸ª")
                insights.append(f"  - ä½æ´»åŠ¨ç¥ç»å…ƒ: {len(pattern['low_activity'])} ä¸ª")
                insights.append(f"  - å¹³å‡æ´»åŠ¨æ°´å¹³: {pattern['mean_activity']:.3f}")
        
        # ç½‘ç»œç‰¹å¾åˆ†æ
        if 'combined' in self.networks:
            network_data = self.networks['combined']
            insights.append(f"\nğŸ•¸ï¸ **ç½‘ç»œæ‹“æ‰‘ç‰¹å¾**:")
            insights.append(f"- ç½‘ç»œå¯†åº¦: **{network_data['density']:.3f}**")
            insights.append(f"- è¿æ¥è¾¹æ•°: **{network_data['edge_count']}**")
            insights.append(f"- è¿æ¥é˜ˆå€¼: **{network_data['threshold']:.3f}**")
        
        # ç ”ç©¶æ„ä¹‰
        insights.append(f"\nğŸ’¡ **ç ”ç©¶æ„ä¹‰**:")
        insights.append(f"- æ­ç¤ºäº†å…³é”®ç¥ç»å…ƒçš„åŠŸèƒ½æ¨¡å—åŒ–ç»„ç»‡")
        insights.append(f"- ä¸åŒç¤¾åŒºå¯èƒ½æ‰¿æ‹…ä¸åŒçš„åŠŸèƒ½è§’è‰²")
        insights.append(f"- ä¸ºç†è§£ç¥ç»ç½‘ç»œçš„ä¿¡æ¯å¤„ç†æœºåˆ¶æä¾›çº¿ç´¢")
        insights.append(f"- å¯æŒ‡å¯¼åç»­çš„é¶å‘ç ”ç©¶å’Œå¹²é¢„ç­–ç•¥")
        
        # ä¿å­˜æ´å¯ŸæŠ¥å‘Š
        insights_text = "\n".join(insights)
        with open('community_insights.md', 'w', encoding='utf-8') as f:
            f.write("# å…³é”®ç¥ç»å…ƒç¤¾åŒºç»“æ„åˆ†ææ´å¯Ÿ\n\n")
            f.write(insights_text)
        
        print("åˆ†ææ´å¯Ÿ:")
        for insight in insights:
            print(insight)
        
        print(f"\næ´å¯ŸæŠ¥å‘Šå·²ä¿å­˜åˆ° 'community_insights.md'")
        
        return insights

def main():
    """ä¸»åˆ†ææµç¨‹"""
    print("=== å…³é”®ç¥ç»å…ƒç¤¾åŒºç»“æ„åˆ†ææ¼”ç¤º ===")
    
    # åˆå§‹åŒ–æ¼”ç¤ºå™¨
    demo = KeyNeuronCommunityDemo(data_path='data/EMtrace02-3æ ‡ç­¾ç‰ˆ.csv')
    
    # åŠ è½½æ•°æ®
    demo.load_data()
    
    # æ„å»ºæ´»åŠ¨ç›¸ä¼¼æ€§ç½‘ç»œ
    demo.build_activity_similarity_networks(similarity_method='euclidean')
    
    # æ£€æµ‹ç¤¾åŒºç»“æ„
    demo.detect_communities(methods=['louvain', 'hierarchical', 'kmeans'])
    
    # åˆ†æè¡Œä¸ºç‰¹å¼‚æ€§æ¨¡å¼
    behavior_patterns = demo.analyze_behavior_specific_patterns()
    
    # å¯è§†åŒ–ç»“æœ
    demo.visualize_community_networks()
    
    # ç”Ÿæˆåˆ†ææ´å¯Ÿ
    insights = demo.generate_community_insights()
    
    print("\n=== æ¼”ç¤ºå®Œæˆ ===")
    print("1. âœ… å·²è¯†åˆ«å…³é”®ç¥ç»å…ƒ")
    print("2. âœ… å·²æ„å»ºåŠŸèƒ½ç½‘ç»œ")
    print("3. âœ… å·²æ£€æµ‹ç¤¾åŒºç»“æ„")
    print("4. âœ… å·²åˆ†æè¡Œä¸ºæ¨¡å¼")
    print("5. âœ… å·²ç”Ÿæˆå¯è§†åŒ–")
    print("6. âœ… å·²ç”Ÿæˆåˆ†ææ´å¯Ÿ")
    
    return {
        'demo': demo,
        'behavior_patterns': behavior_patterns,
        'insights': insights
    }

if __name__ == "__main__":
    results = main()