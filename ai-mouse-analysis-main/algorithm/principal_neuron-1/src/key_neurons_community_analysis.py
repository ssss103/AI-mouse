import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx

# å¯¼å…¥å¹¶åº”ç”¨matplotlibæ ·å¼é…ç½®
try:
    from matplotlib_config import setup_matplotlib_style
    setup_matplotlib_style()
except ImportError:
    print("è­¦å‘Š: æ— æ³•å¯¼å…¥matplotlib_configï¼Œä½¿ç”¨é»˜è®¤å­—ä½“è®¾ç½®")
from scipy.stats import pearsonr, spearmanr
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans, SpectralClustering
import community as community_louvain
from collections import defaultdict, Counter
import warnings
warnings.filterwarnings('ignore')

class KeyNeuronCommunityAnalyzer:
    """
    å…³é”®ç¥ç»å…ƒç¤¾åŒºç»“æ„åˆ†æå™¨
    """
    
    def __init__(self, data_path, effect_size_path=None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            data_path: ç¥ç»å…ƒæ´»åŠ¨æ•°æ®è·¯å¾„
            effect_size_path: æ•ˆåº”é‡æ•°æ®è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        self.data_path = data_path
        self.effect_size_path = effect_size_path
        self.df = None
        self.effect_df = None
        self.key_neurons = None
        self.networks = {}
        self.communities = {}
        
    def load_data(self):
        """åŠ è½½æ•°æ®"""
        print("=== åŠ è½½æ•°æ® ===")
        
        # åŠ è½½ç¥ç»å…ƒæ´»åŠ¨æ•°æ®
        self.df = pd.read_csv(self.data_path)
        neuron_cols = [col for col in self.df.columns if col.startswith('Neuron_')]
        
        print(f"ç¥ç»å…ƒæ´»åŠ¨æ•°æ®:")
        print(f"  - è¡Œä¸ºçŠ¶æ€: {len(self.df)} ä¸ª")
        print(f"  - ç¥ç»å…ƒæ€»æ•°: {len(neuron_cols)} ä¸ª")
        print(f"  - è¡Œä¸ºç±»å‹: {list(self.df['Behavior'].unique())}")
        
        # å¦‚æœæœ‰æ•ˆåº”é‡æ•°æ®ï¼ŒåŠ è½½å¹¶è¯†åˆ«å…³é”®ç¥ç»å…ƒ
        if self.effect_size_path:
            try:
                self.effect_df = pd.read_csv(self.effect_size_path)
                print(f"\næ•ˆåº”é‡æ•°æ®åŠ è½½æˆåŠŸ")
                self.identify_key_neurons()
            except:
                print(f"\næ•ˆåº”é‡æ•°æ®åŠ è½½å¤±è´¥ï¼Œå°†åˆ†ææ‰€æœ‰ç¥ç»å…ƒ")
                self.key_neurons = neuron_cols
        else:
            print(f"\næœªæä¾›æ•ˆåº”é‡æ•°æ®ï¼Œå°†åˆ†ææ‰€æœ‰ç¥ç»å…ƒ")
            self.key_neurons = neuron_cols
            
    def identify_key_neurons(self, effect_threshold=0.5):
        """
        åŸºäºæ•ˆåº”é‡è¯†åˆ«å…³é”®ç¥ç»å…ƒ
        
        Args:
            effect_threshold: æ•ˆåº”é‡é˜ˆå€¼
        """
        print(f"\n=== è¯†åˆ«å…³é”®ç¥ç»å…ƒ (é˜ˆå€¼: {effect_threshold}) ===")
        
        key_neurons_set = set()
        
        # éå†æ¯ä¸ªè¡Œä¸ºçš„æ•ˆåº”é‡æ•°æ®
        behaviors = [col for col in self.effect_df.columns if col != 'Neuron']
        
        for behavior in behaviors:
            if behavior in self.effect_df.columns:
                # æ‰¾å‡ºè¯¥è¡Œä¸ºä¸‹æ•ˆåº”é‡å¤§äºé˜ˆå€¼çš„ç¥ç»å…ƒ
                mask = self.effect_df[behavior].abs() >= effect_threshold
                behavior_key_neurons = self.effect_df[mask]['Neuron'].tolist()
                key_neurons_set.update(behavior_key_neurons)
                print(f"  {behavior}: {len(behavior_key_neurons)} ä¸ªå…³é”®ç¥ç»å…ƒ")
        
        self.key_neurons = list(key_neurons_set)
        print(f"\næ€»å…³é”®ç¥ç»å…ƒæ•°é‡: {len(self.key_neurons)}")
        print(f"å…³é”®ç¥ç»å…ƒå æ¯”: {len(self.key_neurons)/len([col for col in self.df.columns if col.startswith('Neuron_')])*100:.1f}%")
        
        return self.key_neurons
    
    def build_functional_networks(self, correlation_method='pearson', threshold=0.3):
        """
        æ„å»ºåŠŸèƒ½è¿æ¥ç½‘ç»œ
        
        Args:
            correlation_method: ç›¸å…³æ€§è®¡ç®—æ–¹æ³• ('pearson' æˆ– 'spearman')
            threshold: è¿æ¥å¼ºåº¦é˜ˆå€¼
        """
        print(f"\n=== æ„å»ºåŠŸèƒ½è¿æ¥ç½‘ç»œ ===")
        print(f"ç›¸å…³æ€§æ–¹æ³•: {correlation_method}")
        print(f"è¿æ¥é˜ˆå€¼: {threshold}")
        
        behaviors = self.df['Behavior'].unique()
        
        for behavior in behaviors:
            print(f"\næ„å»º {behavior} è¡Œä¸ºçš„ç½‘ç»œ...")
            
            # è·å–è¯¥è¡Œä¸ºçŠ¶æ€ä¸‹çš„ç¥ç»å…ƒæ´»åŠ¨æ•°æ®
            behavior_data = self.df[self.df['Behavior'] == behavior]
            if len(behavior_data) == 0:
                continue
                
            # æå–å…³é”®ç¥ç»å…ƒçš„æ´»åŠ¨
            key_neuron_data = behavior_data[self.key_neurons].T  # è½¬ç½®ï¼Œè¡Œä¸ºç¥ç»å…ƒï¼Œåˆ—ä¸ºæ ·æœ¬
            
            # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
            n_neurons = len(self.key_neurons)
            correlation_matrix = np.zeros((n_neurons, n_neurons))
            p_values = np.zeros((n_neurons, n_neurons))
            
            for i in range(n_neurons):
                for j in range(i, n_neurons):
                    if i == j:
                        correlation_matrix[i, j] = 1.0
                        p_values[i, j] = 0.0
                    else:
                        data_i = key_neuron_data.iloc[i].values
                        data_j = key_neuron_data.iloc[j].values
                        
                        if correlation_method == 'pearson':
                            corr, p_val = pearsonr(data_i, data_j)
                        else:
                            corr, p_val = spearmanr(data_i, data_j)
                        
                        correlation_matrix[i, j] = corr
                        correlation_matrix[j, i] = corr
                        p_values[i, j] = p_val
                        p_values[j, i] = p_val
            
            # æ„å»ºç½‘ç»œå›¾
            G = nx.Graph()
            
            # æ·»åŠ èŠ‚ç‚¹
            for neuron in self.key_neurons:
                G.add_node(neuron)
            
            # æ·»åŠ è¾¹ï¼ˆåŸºäºé˜ˆå€¼ï¼‰
            edge_count = 0
            for i in range(n_neurons):
                for j in range(i+1, n_neurons):
                    if abs(correlation_matrix[i, j]) >= threshold:
                        G.add_edge(
                            self.key_neurons[i], 
                            self.key_neurons[j], 
                            weight=abs(correlation_matrix[i, j]),
                            correlation=correlation_matrix[i, j],
                            p_value=p_values[i, j]
                        )
                        edge_count += 1
            
            self.networks[behavior] = {
                'graph': G,
                'correlation_matrix': correlation_matrix,
                'p_values': p_values,
                'edge_count': edge_count,
                'density': nx.density(G)
            }
            
            print(f"  èŠ‚ç‚¹æ•°: {G.number_of_nodes()}")
            print(f"  è¾¹æ•°: {edge_count}")
            print(f"  ç½‘ç»œå¯†åº¦: {nx.density(G):.3f}")
    
    def detect_communities(self, methods=['louvain', 'spectral', 'hierarchical']):
        """
        ä½¿ç”¨å¤šç§æ–¹æ³•æ£€æµ‹ç¤¾åŒºç»“æ„
        
        Args:
            methods: ç¤¾åŒºæ£€æµ‹æ–¹æ³•åˆ—è¡¨
        """
        print(f"\n=== ç¤¾åŒºæ£€æµ‹ ===")
        
        for behavior, network_data in self.networks.items():
            print(f"\nåˆ†æ {behavior} è¡Œä¸ºçš„ç¤¾åŒºç»“æ„:")
            G = network_data['graph']
            
            behavior_communities = {}
            
            # 1. Louvainç®—æ³•
            if 'louvain' in methods:
                try:
                    louvain_communities = community_louvain.best_partition(G)
                    n_communities = len(set(louvain_communities.values()))
                    modularity = community_louvain.modularity(louvain_communities, G)
                    
                    behavior_communities['louvain'] = {
                        'partition': louvain_communities,
                        'n_communities': n_communities,
                        'modularity': modularity
                    }
                    print(f"  Louvain: {n_communities} ä¸ªç¤¾åŒº, æ¨¡å—åº¦ = {modularity:.3f}")
                except:
                    print(f"  Louvainç®—æ³•å¤±è´¥")
            
            # 2. è°±èšç±»
            if 'spectral' in methods and G.number_of_edges() > 0:
                try:
                    # è·å–é‚»æ¥çŸ©é˜µ
                    adj_matrix = nx.adjacency_matrix(G).todense()
                    
                    # å°è¯•ä¸åŒçš„èšç±»æ•°
                    best_spectral = None
                    best_silhouette = -1
                    
                    for n_clusters in range(2, min(8, G.number_of_nodes())):
                        spectral = SpectralClustering(n_clusters=n_clusters, random_state=42)
                        try:
                            labels = spectral.fit_predict(adj_matrix)
                            # è¿™é‡Œå¯ä»¥è®¡ç®—è½®å»“ç³»æ•°ï¼Œä½†ç®€åŒ–å¤„ç†
                            spectral_communities = {node: label for node, label in zip(G.nodes(), labels)}
                            
                            if best_spectral is None:
                                best_spectral = {
                                    'partition': spectral_communities,
                                    'n_communities': n_clusters
                                }
                        except:
                            continue
                    
                    if best_spectral:
                        behavior_communities['spectral'] = best_spectral
                        print(f"  è°±èšç±»: {best_spectral['n_communities']} ä¸ªç¤¾åŒº")
                except:
                    print(f"  è°±èšç±»å¤±è´¥")
            
            # 3. å±‚æ¬¡èšç±»
            if 'hierarchical' in methods and G.number_of_edges() > 0:
                try:
                    # ä½¿ç”¨ç›¸å…³æ€§çŸ©é˜µè¿›è¡Œå±‚æ¬¡èšç±»
                    correlation_matrix = network_data['correlation_matrix']
                    distance_matrix = 1 - np.abs(correlation_matrix)
                    
                    # æ‰§è¡Œå±‚æ¬¡èšç±»
                    linkage_matrix = linkage(distance_matrix, method='ward')
                    
                    # ç¡®å®šæœ€ä¼˜èšç±»æ•°ï¼ˆç®€åŒ–å¤„ç†ï¼Œä½¿ç”¨å›ºå®šæ•°ç›®ï¼‰
                    n_clusters = min(5, len(self.key_neurons) // 3)
                    if n_clusters >= 2:
                        cluster_labels = fcluster(linkage_matrix, n_clusters, criterion='maxclust')
                        
                        hierarchical_communities = {
                            neuron: label for neuron, label in zip(self.key_neurons, cluster_labels)
                        }
                        
                        behavior_communities['hierarchical'] = {
                            'partition': hierarchical_communities,
                            'n_communities': n_clusters,
                            'linkage_matrix': linkage_matrix
                        }
                        print(f"  å±‚æ¬¡èšç±»: {n_clusters} ä¸ªç¤¾åŒº")
                except:
                    print(f"  å±‚æ¬¡èšç±»å¤±è´¥")
            
            self.communities[behavior] = behavior_communities
    
    def analyze_community_characteristics(self):
        """åˆ†æç¤¾åŒºç‰¹å¾"""
        print(f"\n=== ç¤¾åŒºç‰¹å¾åˆ†æ ===")
        
        community_analysis = {}
        
        for behavior, communities in self.communities.items():
            print(f"\n{behavior} è¡Œä¸ºçš„ç¤¾åŒºç‰¹å¾:")
            behavior_analysis = {}
            
            G = self.networks[behavior]['graph']
            
            for method, community_data in communities.items():
                partition = community_data['partition']
                n_communities = community_data['n_communities']
                
                print(f"\n  {method} æ–¹æ³•:")
                print(f"    ç¤¾åŒºæ•°é‡: {n_communities}")
                
                # åˆ†ææ¯ä¸ªç¤¾åŒºçš„ç‰¹å¾
                community_stats = {}
                for community_id in range(n_communities):
                    # è·å–è¯¥ç¤¾åŒºçš„ç¥ç»å…ƒ
                    community_neurons = [node for node, comm in partition.items() if comm == community_id]
                    
                    if len(community_neurons) > 0:
                        # ç¤¾åŒºå¤§å°
                        size = len(community_neurons)
                        
                        # ç¤¾åŒºå†…è¿æ¥
                        subgraph = G.subgraph(community_neurons)
                        internal_edges = subgraph.number_of_edges()
                        
                        # è®¡ç®—ç¤¾åŒºå†…è¿æ¥å¯†åº¦
                        max_internal_edges = size * (size - 1) / 2
                        internal_density = internal_edges / max_internal_edges if max_internal_edges > 0 else 0
                        
                        community_stats[community_id] = {
                            'neurons': community_neurons,
                            'size': size,
                            'internal_edges': internal_edges,
                            'internal_density': internal_density
                        }
                        
                        print(f"      ç¤¾åŒº {community_id}: {size} ä¸ªç¥ç»å…ƒ, å†…éƒ¨å¯†åº¦ = {internal_density:.3f}")
                
                behavior_analysis[method] = community_stats
            
            community_analysis[behavior] = behavior_analysis
        
        return community_analysis
    
    def compare_communities_across_behaviors(self):
        """æ¯”è¾ƒä¸åŒè¡Œä¸ºçŠ¶æ€ä¸‹çš„ç¤¾åŒºç»“æ„"""
        print(f"\n=== è·¨è¡Œä¸ºç¤¾åŒºç»“æ„æ¯”è¾ƒ ===")
        
        # ä½¿ç”¨Louvainæ–¹æ³•çš„ç»“æœè¿›è¡Œæ¯”è¾ƒ
        louvain_communities = {}
        for behavior, communities in self.communities.items():
            if 'louvain' in communities:
                louvain_communities[behavior] = communities['louvain']['partition']
        
        if len(louvain_communities) < 2:
            print("éœ€è¦è‡³å°‘ä¸¤ä¸ªè¡Œä¸ºçŠ¶æ€æ‰èƒ½è¿›è¡Œæ¯”è¾ƒ")
            return
        
        behaviors = list(louvain_communities.keys())
        
        print(f"æ¯”è¾ƒè¡Œä¸º: {behaviors}")
        
        # è®¡ç®—ç¤¾åŒºç»“æ„ç›¸ä¼¼æ€§
        for i in range(len(behaviors)):
            for j in range(i+1, len(behaviors)):
                behavior1, behavior2 = behaviors[i], behaviors[j]
                partition1 = louvain_communities[behavior1]
                partition2 = louvain_communities[behavior2]
                
                # è®¡ç®—è°ƒæ•´å…°å¾·æŒ‡æ•°ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
                common_neurons = set(partition1.keys()) & set(partition2.keys())
                if len(common_neurons) > 0:
                    # ç®€åŒ–çš„ç›¸ä¼¼æ€§è®¡ç®—ï¼šç›¸åŒç¤¾åŒºåˆ†é…çš„ç¥ç»å…ƒæ¯”ä¾‹
                    same_assignment = sum(1 for neuron in common_neurons 
                                        if partition1[neuron] == partition2[neuron])
                    similarity = same_assignment / len(common_neurons)
                    
                    print(f"  {behavior1} vs {behavior2}: ç›¸ä¼¼åº¦ = {similarity:.3f}")
        
        return louvain_communities
    
    def visualize_networks_and_communities(self, save_plots=True):
        """å¯è§†åŒ–ç½‘ç»œå’Œç¤¾åŒºç»“æ„"""
        print(f"\n=== ç½‘ç»œå’Œç¤¾åŒºå¯è§†åŒ– ===")
        
        if save_plots:
            import os
            plot_dir = "community_analysis_plots"
            if not os.path.exists(plot_dir):
                os.makedirs(plot_dir)
        
        behaviors = list(self.networks.keys())
        n_behaviors = len(behaviors)
        
        # ä¸ºæ¯ä¸ªè¡Œä¸ºåˆ›å»ºç½‘ç»œå¯è§†åŒ–
        for behavior in behaviors:
            if behavior not in self.communities or 'louvain' not in self.communities[behavior]:
                continue
                
            G = self.networks[behavior]['graph']
            partition = self.communities[behavior]['louvain']['partition']
            
            # åˆ›å»ºå›¾å½¢
            plt.figure(figsize=(12, 10))
            
            # è®¾ç½®å¸ƒå±€
            if G.number_of_nodes() > 0:
                try:
                    pos = nx.spring_layout(G, k=1, iterations=50)
                except:
                    pos = nx.random_layout(G)
                
                # ç»˜åˆ¶è¾¹
                nx.draw_networkx_edges(G, pos, alpha=0.5, width=0.5, edge_color='gray')
                
                # ä¸ºä¸åŒç¤¾åŒºè®¾ç½®ä¸åŒé¢œè‰²
                unique_communities = set(partition.values())
                colors = plt.cm.Set3(np.linspace(0, 1, len(unique_communities)))
                
                for i, community in enumerate(unique_communities):
                    community_nodes = [node for node, comm in partition.items() if comm == community]
                    nx.draw_networkx_nodes(G, pos, nodelist=community_nodes, 
                                         node_color=[colors[i]], node_size=300, alpha=0.8)
                
                # ç»˜åˆ¶æ ‡ç­¾
                nx.draw_networkx_labels(G, pos, font_size=8)
            
            plt.title(f'{behavior} è¡Œä¸ºçš„ç¥ç»å…ƒç½‘ç»œå’Œç¤¾åŒºç»“æ„', fontsize=16, fontweight='bold')
            plt.axis('off')
            
            if save_plots:
                plt.savefig(f"{plot_dir}/network_{behavior}.png", dpi=300, bbox_inches='tight')
            plt.show()
        
        # åˆ›å»ºç¤¾åŒºç»Ÿè®¡æ±‡æ€»å›¾
        self._plot_community_statistics(save_plots, plot_dir if save_plots else None)
    
    def _plot_community_statistics(self, save_plots=True, plot_dir=None):
        """ç»˜åˆ¶ç¤¾åŒºç»Ÿè®¡å›¾è¡¨"""
        
        # æ”¶é›†ç»Ÿè®¡æ•°æ®
        stats_data = []
        for behavior, communities in self.communities.items():
            if 'louvain' in communities:
                stats_data.append({
                    'Behavior': behavior,
                    'N_Communities': communities['louvain']['n_communities'],
                    'Modularity': communities['louvain']['modularity'],
                    'Network_Density': self.networks[behavior]['density']
                })
        
        if not stats_data:
            return
        
        stats_df = pd.DataFrame(stats_data)
        
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('ç¤¾åŒºç»“æ„ç»Ÿè®¡åˆ†æ', fontsize=16)
        
        # 1. ç¤¾åŒºæ•°é‡
        ax1 = axes[0, 0]
        bars1 = ax1.bar(stats_df['Behavior'], stats_df['N_Communities'], 
                       color='skyblue', alpha=0.7)
        ax1.set_title('å„è¡Œä¸ºçŠ¶æ€çš„ç¤¾åŒºæ•°é‡', fontsize=14, fontweight='bold')
        ax1.set_ylabel('ç¤¾åŒºæ•°é‡', fontsize=12, fontweight='bold')
        ax1.tick_params(axis='x', rotation=45, labelsize=10, labelweight='bold')
        ax1.tick_params(axis='y', labelsize=10, labelweight='bold')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars1:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{int(height)}', ha='center', va='bottom')
        
        # 2. æ¨¡å—åº¦
        ax2 = axes[0, 1]
        bars2 = ax2.bar(stats_df['Behavior'], stats_df['Modularity'], 
                       color='lightgreen', alpha=0.7)
        ax2.set_title('å„è¡Œä¸ºçŠ¶æ€çš„æ¨¡å—åº¦', fontsize=14, fontweight='bold')
        ax2.set_ylabel('æ¨¡å—åº¦', fontsize=12, fontweight='bold')
        ax2.tick_params(axis='x', rotation=45, labelsize=10, labelweight='bold')
        ax2.tick_params(axis='y', labelsize=10, labelweight='bold')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars2:
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.3f}', ha='center', va='bottom')
        
        # 3. ç½‘ç»œå¯†åº¦
        ax3 = axes[1, 0]
        bars3 = ax3.bar(stats_df['Behavior'], stats_df['Network_Density'], 
                       color='orange', alpha=0.7)
        ax3.set_title('å„è¡Œä¸ºçŠ¶æ€çš„ç½‘ç»œå¯†åº¦', fontsize=14, fontweight='bold')
        ax3.set_ylabel('ç½‘ç»œå¯†åº¦', fontsize=12, fontweight='bold')
        ax3.tick_params(axis='x', rotation=45, labelsize=10, labelweight='bold')
        ax3.tick_params(axis='y', labelsize=10, labelweight='bold')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars3:
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.3f}', ha='center', va='bottom')
        
        # 4. å…³ç³»æ•£ç‚¹å›¾
        ax4 = axes[1, 1]
        scatter = ax4.scatter(stats_df['Network_Density'], stats_df['Modularity'], 
                            c=stats_df['N_Communities'], cmap='viridis', s=100, alpha=0.7)
        ax4.set_xlabel('ç½‘ç»œå¯†åº¦', fontsize=12, fontweight='bold')
        ax4.set_ylabel('æ¨¡å—åº¦', fontsize=12, fontweight='bold')
        ax4.set_title('ç½‘ç»œå¯†åº¦ vs æ¨¡å—åº¦', fontsize=14, fontweight='bold')
        ax4.tick_params(axis='both', labelsize=10, labelweight='bold')
        
        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(scatter, ax=ax4)
        cbar.set_label('ç¤¾åŒºæ•°é‡')
        
        # æ·»åŠ è¡Œä¸ºæ ‡ç­¾
        for i, row in stats_df.iterrows():
            ax4.annotate(row['Behavior'], 
                        (row['Network_Density'], row['Modularity']),
                        xytext=(5, 5), textcoords='offset points', fontsize=8)
        
        plt.tight_layout()
        
        if save_plots and plot_dir:
            plt.savefig(f"{plot_dir}/community_statistics.png", dpi=300, bbox_inches='tight')
        plt.show()
    
    def generate_community_report(self):
        """ç”Ÿæˆç¤¾åŒºåˆ†ææŠ¥å‘Š"""
        print(f"\n=== ç”Ÿæˆç¤¾åŒºåˆ†ææŠ¥å‘Š ===")
        
        report = []
        report.append("# å…³é”®ç¥ç»å…ƒç¤¾åŒºç»“æ„åˆ†ææŠ¥å‘Š\n")
        
        # æ•°æ®æ¦‚è§ˆ
        report.append("## ğŸ“Š æ•°æ®æ¦‚è§ˆ\n")
        report.append(f"- **å…³é”®ç¥ç»å…ƒæ•°é‡**: {len(self.key_neurons)}\n")
        report.append(f"- **åˆ†æè¡Œä¸ºçŠ¶æ€**: {list(self.networks.keys())}\n")
        report.append(f"- **ç½‘ç»œæ„å»ºæ–¹æ³•**: åŠŸèƒ½è¿æ¥ï¼ˆç›¸å…³æ€§ï¼‰\n")
        report.append(f"- **ç¤¾åŒºæ£€æµ‹æ–¹æ³•**: Louvainã€è°±èšç±»ã€å±‚æ¬¡èšç±»\n\n")
        
        # ç½‘ç»œç‰¹å¾
        report.append("## ğŸ•¸ï¸ ç½‘ç»œç‰¹å¾\n")
        for behavior, network_data in self.networks.items():
            G = network_data['graph']
            report.append(f"### {behavior} è¡Œä¸ºç½‘ç»œ\n")
            report.append(f"- **èŠ‚ç‚¹æ•°**: {G.number_of_nodes()}\n")
            report.append(f"- **è¾¹æ•°**: {network_data['edge_count']}\n")
            report.append(f"- **ç½‘ç»œå¯†åº¦**: {network_data['density']:.3f}\n")
            
            if behavior in self.communities and 'louvain' in self.communities[behavior]:
                louvain_data = self.communities[behavior]['louvain']
                report.append(f"- **ç¤¾åŒºæ•°é‡**: {louvain_data['n_communities']}\n")
                report.append(f"- **æ¨¡å—åº¦**: {louvain_data['modularity']:.3f}\n")
            report.append("\n")
        
        # ç¤¾åŒºåˆ†æç»“æœ
        report.append("## ğŸ˜ï¸ ç¤¾åŒºç»“æ„åˆ†æ\n")
        
        for behavior, communities in self.communities.items():
            report.append(f"### {behavior} è¡Œä¸ºç¤¾åŒº\n")
            
            for method, community_data in communities.items():
                report.append(f"#### {method.title()} æ–¹æ³•\n")
                report.append(f"- **ç¤¾åŒºæ•°é‡**: {community_data['n_communities']}\n")
                
                if 'modularity' in community_data:
                    report.append(f"- **æ¨¡å—åº¦**: {community_data['modularity']:.3f}\n")
                
                # åˆ—å‡ºå„ç¤¾åŒºçš„ç¥ç»å…ƒ
                partition = community_data['partition']
                community_neurons = defaultdict(list)
                for neuron, comm_id in partition.items():
                    community_neurons[comm_id].append(neuron)
                
                for comm_id, neurons in community_neurons.items():
                    report.append(f"  - **ç¤¾åŒº {comm_id}**: {neurons}\n")
                
                report.append("\n")
        
        # ä¿å­˜æŠ¥å‘Š
        report_text = "".join(report)
        with open('community_analysis_report.md', 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        print("æŠ¥å‘Šå·²ä¿å­˜åˆ° 'community_analysis_report.md'")
        
        return report_text

def main():
    """ä¸»åˆ†ææµç¨‹"""
    print("=== å…³é”®ç¥ç»å…ƒç¤¾åŒºç»“æ„åˆ†æ ===")
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = KeyNeuronCommunityAnalyzer(
        data_path='data/EMtrace02-3æ ‡ç­¾ç‰ˆ.csv',
        effect_size_path=None  # å¦‚æœæœ‰æ•ˆåº”é‡æ•°æ®ï¼Œè¯·æä¾›è·¯å¾„
    )
    
    # åŠ è½½æ•°æ®
    analyzer.load_data()
    
    # æ„å»ºåŠŸèƒ½è¿æ¥ç½‘ç»œ
    analyzer.build_functional_networks(
        correlation_method='pearson',
        threshold=0.3
    )
    
    # æ£€æµ‹ç¤¾åŒºç»“æ„
    analyzer.detect_communities(methods=['louvain', 'spectral', 'hierarchical'])
    
    # åˆ†æç¤¾åŒºç‰¹å¾
    community_characteristics = analyzer.analyze_community_characteristics()
    
    # æ¯”è¾ƒä¸åŒè¡Œä¸ºçš„ç¤¾åŒºç»“æ„
    community_comparison = analyzer.compare_communities_across_behaviors()
    
    # å¯è§†åŒ–ç»“æœ
    analyzer.visualize_networks_and_communities()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_community_report()
    
    print("\n=== åˆ†æå®Œæˆ ===")
    print("1. å·²æ„å»ºåŠŸèƒ½è¿æ¥ç½‘ç»œ")
    print("2. å·²æ£€æµ‹ç¤¾åŒºç»“æ„")
    print("3. å·²åˆ†æç¤¾åŒºç‰¹å¾")
    print("4. å·²ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
    print("5. å·²ç”Ÿæˆåˆ†ææŠ¥å‘Š")
    
    return {
        'analyzer': analyzer,
        'characteristics': community_characteristics,
        'comparison': community_comparison,
        'report': report
    }

if __name__ == "__main__":
    results = main()